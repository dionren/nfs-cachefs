# FUSE + io_uring é«˜æ€§èƒ½æ”¹é€ æ–¹æ¡ˆ

## æ‰§è¡Œæ‘˜è¦

æœ¬æ–¹æ¡ˆæ—¨åœ¨é€šè¿‡é›†æˆ io_uring æŠ€æœ¯ï¼Œå½»åº•æ”¹é€  NFS-CacheFS çš„ I/O æ€§èƒ½ï¼Œå®ç°æ¥è¿‘ç¡¬ä»¶æé™çš„è¯»å–é€Ÿåº¦ã€‚

### æ ¸å¿ƒæ”¶ç›Š
- **ç¼“å­˜å‘½ä¸­æ€§èƒ½**: 100 MB/s â†’ 2-3 GB/s (20-30å€æå‡)
- **ç¼“å­˜æœªå‘½ä¸­æ€§èƒ½**: 60 MB/s â†’ 200-500 MB/s (3-8å€æå‡)
- **CPUä½¿ç”¨ç‡**: é™ä½ 50-70%
- **ç³»ç»Ÿè°ƒç”¨å¼€é”€**: å‡å°‘ 80%

## ç°çŠ¶åˆ†æ

### å½“å‰æ¶æ„é—®é¢˜
1. **åŒæ­¥I/Oç“¶é¢ˆ**
   - æ¯æ¬¡è¯»å–éƒ½æ¶‰åŠç”¨æˆ·æ€/å†…æ ¸æ€åˆ‡æ¢
   - æ— æ³•æ‰¹é‡å¤„ç†è¯·æ±‚
   - ç¼ºä¹çœŸæ­£çš„å¼‚æ­¥I/Oèƒ½åŠ›

2. **å†…å­˜æ‹·è´è¿‡å¤š**
   - FUSE â†’ ç”¨æˆ·ç¼“å†²åŒº â†’ å†…æ ¸ç¼“å†²åŒº â†’ ç£ç›˜
   - å¤§æ–‡ä»¶è¯»å–æ—¶å†…å­˜å¸¦å®½æˆä¸ºç“¶é¢ˆ

3. **ç³»ç»Ÿè°ƒç”¨å¼€é”€**
   - æ¯ä¸ªè¯»è¯·æ±‚è‡³å°‘2æ¬¡ç³»ç»Ÿè°ƒç”¨
   - é«˜å¹¶å‘æ—¶ä¸Šä¸‹æ–‡åˆ‡æ¢ä¸¥é‡

### ç°æœ‰ä¼˜åŒ–æªæ–½
- æ™ºèƒ½ç¼“å­˜ç­–ç•¥ (SmartCacheConfig)
- é›¶æ‹·è´è¯»å– (O_DIRECT)
- å¤§å—è¯»å– (64MB blocks)
- åŒæ­¥ç›´è¯»ç¼“å­˜

## io_uring æŠ€æœ¯ä¼˜åŠ¿

### æ ¸å¿ƒç‰¹æ€§
1. **çœŸæ­£çš„å¼‚æ­¥I/O**
   - æäº¤å’Œå®Œæˆåˆ†ç¦»
   - æ‰¹é‡æ“ä½œæ”¯æŒ
   - æ— éœ€çº¿ç¨‹æ± 

2. **é›¶ç³»ç»Ÿè°ƒç”¨å¼€é”€**
   - å…±äº«å†…å­˜ç¯å½¢ç¼“å†²åŒº
   - å†…æ ¸è½®è¯¢æ¨¡å¼ (SQPOLL)
   - ç”¨æˆ·æ€ç›´æ¥æäº¤

3. **é«˜çº§ç‰¹æ€§**
   - å›ºå®šç¼“å†²åŒº (å‡å°‘æ˜ å°„å¼€é”€)
   - é“¾å¼æ“ä½œ (è¯»å†™åŸå­æ€§)
   - ä¼˜å…ˆçº§å’Œè°ƒåº¦æ§åˆ¶

## æ”¹é€ æ–¹æ¡ˆ

### ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€è®¾æ–½ (1å‘¨)

#### 1.1 æ·»åŠ ä¾èµ–
```toml
# Cargo.toml
[dependencies]
io-uring = "0.6"
tokio-uring = "0.5"  # å¯é€‰ï¼Œç”¨äºä¸tokioé›†æˆ

[features]
io_uring = ["io-uring", "tokio-uring"]
```

#### 1.2 åˆ›å»º io_uring æ¨¡å—
```rust
// src/io/mod.rs
pub mod uring;

// src/io/uring.rs
use io_uring::{IoUring, opcode, types};
use std::sync::Arc;
use parking_lot::Mutex;

pub struct IoUringExecutor {
    ring: Arc<Mutex<IoUring>>,
    config: IoUringConfig,
    buffer_pool: BufferPool,
    metrics: IoUringMetrics,
}

pub struct IoUringConfig {
    pub queue_depth: u32,
    pub sq_poll: bool,
    pub io_poll: bool,
    pub fixed_buffers: bool,
    pub huge_pages: bool,
}

impl IoUringExecutor {
    pub fn new(config: IoUringConfig) -> Result<Self> {
        let mut builder = IoUring::builder();
        
        if config.sq_poll {
            builder.setup_sqpoll(1000); // 1ms idle time
        }
        
        if config.io_poll {
            builder.setup_iopoll();
        }
        
        let ring = builder
            .queue_depth(config.queue_depth)
            .build()?;
            
        Ok(Self {
            ring: Arc::new(Mutex::new(ring)),
            config,
            buffer_pool: BufferPool::new(config.queue_depth as usize),
            metrics: IoUringMetrics::new(),
        })
    }
    
    pub async fn read_direct(&self, fd: i32, offset: u64, size: u32) -> Result<Vec<u8>> {
        // å®ç°ç›´æ¥è¯»å–
    }
    
    pub async fn read_fixed(&self, fd: i32, offset: u64, buf_index: u16, size: u32) -> Result<()> {
        // ä½¿ç”¨å›ºå®šç¼“å†²åŒºè¯»å–
    }
}
```

#### 1.3 ç¼“å†²åŒºç®¡ç†
```rust
// src/io/buffer.rs
pub struct BufferPool {
    buffers: Vec<AlignedBuffer>,
    free_list: Arc<Mutex<Vec<usize>>>,
}

pub struct AlignedBuffer {
    ptr: *mut u8,
    size: usize,
    alignment: usize,
}

impl AlignedBuffer {
    pub fn new(size: usize) -> Self {
        // åˆ†é…å¯¹é½çš„å†…å­˜ï¼Œæ”¯æŒ O_DIRECT
        let alignment = 512; // æ‰‡åŒºå¯¹é½
        let layout = Layout::from_size_align(size, alignment).unwrap();
        let ptr = unsafe { alloc::alloc(layout) };
        
        Self { ptr, size, alignment }
    }
}
```

### ç¬¬äºŒé˜¶æ®µï¼šç¼“å­˜è¯»å–ä¼˜åŒ– (1å‘¨)

#### 2.1 ä¿®æ”¹ CacheFs::read
```rust
// src/fs/cachefs.rs
impl CacheFs {
    fn read(&mut self, ...) {
        // æ£€æŸ¥æ˜¯å¦å¯ç”¨ io_uring
        if self.config.nvme.use_io_uring {
            self.read_with_uring(ino, offset, size, reply)
        } else {
            self.read_legacy(ino, offset, size, reply)
        }
    }
    
    fn read_with_uring(&mut self, ino: u64, offset: i64, size: u32, reply: ReplyData) {
        let path = match self.inode_manager.get_path(ino) {
            Some(path) => path,
            None => {
                reply.error(libc::ENOENT);
                return;
            }
        };
        
        let cache_path = self.get_cache_path(&path);
        
        // ç¼“å­˜å‘½ä¸­ - ä½¿ç”¨ io_uring ä¼˜åŒ–è·¯å¾„
        if cache_path.exists() {
            let uring = self.io_uring_executor.clone();
            
            tokio::spawn(async move {
                match uring.read_direct_to_fuse(cache_path, offset, size).await {
                    Ok(data) => reply.data(&data),
                    Err(e) => reply.error(libc::EIO),
                }
            });
            
            return;
        }
        
        // ç¼“å­˜æœªå‘½ä¸­ - é™çº§åˆ°åŸæœ‰é€»è¾‘
        self.read_legacy(ino, offset, size, reply)
    }
}
```

#### 2.2 å®ç°é›¶æ‹·è´è¯»å–
```rust
// src/io/uring.rs
impl IoUringExecutor {
    pub async fn read_direct_to_fuse(
        &self, 
        path: PathBuf, 
        offset: i64, 
        size: u32
    ) -> Result<Vec<u8>> {
        let file = std::fs::File::open(path)?;
        let fd = file.as_raw_fd();
        
        // è·å–é¢„åˆ†é…çš„ç¼“å†²åŒº
        let (buf_index, buffer) = self.buffer_pool.acquire().await?;
        
        // æ„å»ºè¯»å–æ“ä½œ
        let read_op = opcode::Read::new(
            types::Fd(fd), 
            buffer.as_mut_ptr(), 
            size
        )
        .offset(offset as u64)
        .build();
        
        // æäº¤å¹¶ç­‰å¾…å®Œæˆ
        let mut ring = self.ring.lock();
        unsafe {
            ring.submission()
                .push(&read_op)
                .expect("submission queue full");
        }
        
        ring.submit_and_wait(1)?;
        
        // è·å–ç»“æœ
        let cqe = ring.completion().next().unwrap();
        let bytes_read = cqe.result();
        
        if bytes_read < 0 {
            return Err(io::Error::from_raw_os_error(-bytes_read));
        }
        
        // è¿”å›æ•°æ®
        let data = buffer.to_vec(bytes_read as usize);
        self.buffer_pool.release(buf_index);
        
        Ok(data)
    }
}
```

### ç¬¬ä¸‰é˜¶æ®µï¼šç¼“å­˜å†™å…¥ä¼˜åŒ– (1å‘¨)

#### 3.1 é“¾å¼æ“ä½œä¼˜åŒ–
```rust
// src/cache/manager.rs
impl CacheManager {
    async fn copy_file_with_uring(
        &self,
        source: PathBuf,
        dest: PathBuf,
        size: u64,
    ) -> Result<()> {
        let uring = self.io_uring_executor.clone();
        
        // ä½¿ç”¨ splice è¿›è¡Œé›¶æ‹·è´
        uring.splice_file(source, dest, size).await?;
        
        Ok(())
    }
}

// src/io/uring.rs
impl IoUringExecutor {
    pub async fn splice_file(
        &self,
        source: PathBuf,
        dest: PathBuf,
        size: u64,
    ) -> Result<()> {
        let src_file = File::open(source)?;
        let dst_file = File::create(dest)?;
        
        let src_fd = src_file.as_raw_fd();
        let dst_fd = dst_file.as_raw_fd();
        
        // åˆ›å»ºç®¡é“ç”¨äº splice
        let (pipe_r, pipe_w) = pipe2(O_CLOEXEC)?;
        
        let mut offset = 0u64;
        let chunk_size = 1024 * 1024 * 16; // 16MB chunks
        
        while offset < size {
            let to_copy = (size - offset).min(chunk_size);
            
            // é“¾å¼æ“ä½œ: read -> pipe -> write
            let splice_in = opcode::Splice::new(
                types::Fd(src_fd),
                offset as i64,
                types::Fd(pipe_w),
                -1,
                to_copy as u32,
            )
            .build();
            
            let splice_out = opcode::Splice::new(
                types::Fd(pipe_r),
                -1,
                types::Fd(dst_fd),
                offset as i64,
                to_copy as u32,
            )
            .build();
            
            // æäº¤é“¾å¼æ“ä½œ
            let mut ring = self.ring.lock();
            unsafe {
                ring.submission()
                    .push(&splice_in)
                    .expect("submission queue full");
                ring.submission()
                    .push(&splice_out)
                    .expect("submission queue full");
            }
            
            ring.submit_and_wait(2)?;
            
            // å¤„ç†å®Œæˆäº‹ä»¶
            for _ in 0..2 {
                let cqe = ring.completion().next().unwrap();
                if cqe.result() < 0 {
                    return Err(io::Error::from_raw_os_error(-cqe.result()));
                }
            }
            
            offset += to_copy;
        }
        
        Ok(())
    }
}
```

### ç¬¬å››é˜¶æ®µï¼šé«˜çº§ä¼˜åŒ– (2å‘¨)

#### 4.1 æ‰¹é‡I/Oå¤„ç†
```rust
pub struct BatchIoRequest {
    requests: Vec<IoRequest>,
    completion_handler: Box<dyn Fn(Vec<IoResult>) + Send>,
}

impl IoUringExecutor {
    pub async fn submit_batch(&self, batch: BatchIoRequest) -> Result<()> {
        let mut ring = self.ring.lock();
        
        // æ‰¹é‡æäº¤æ‰€æœ‰è¯·æ±‚
        for req in &batch.requests {
            let sqe = match req {
                IoRequest::Read { fd, offset, size, buf_index } => {
                    opcode::Read::new(
                        types::Fd(*fd),
                        self.buffer_pool.get_buffer(*buf_index).as_mut_ptr(),
                        *size
                    )
                    .offset(*offset)
                    .build()
                }
                IoRequest::Write { fd, offset, size, buf_index } => {
                    // ç±»ä¼¼å¤„ç†å†™è¯·æ±‚
                }
            };
            
            unsafe {
                ring.submission().push(&sqe)?;
            }
        }
        
        // ä¸€æ¬¡æ€§æäº¤æ‰€æœ‰è¯·æ±‚
        ring.submit()?;
        
        // å¼‚æ­¥ç­‰å¾…å®Œæˆ
        tokio::spawn(async move {
            let results = self.wait_batch_completion(batch.requests.len()).await;
            (batch.completion_handler)(results);
        });
        
        Ok(())
    }
}
```

#### 4.2 è‡ªé€‚åº”é¢„è¯»
```rust
pub struct AdaptiveReadahead {
    history: VecDeque<ReadPattern>,
    predictor: ReadPredictor,
    prefetch_queue: Arc<Mutex<VecDeque<PrefetchRequest>>>,
}

impl AdaptiveReadahead {
    pub fn on_read(&mut self, path: &Path, offset: u64, size: u32) {
        // è®°å½•è¯»å–æ¨¡å¼
        self.history.push_back(ReadPattern {
            path: path.to_owned(),
            offset,
            size,
            timestamp: Instant::now(),
        });
        
        // é¢„æµ‹ä¸‹ä¸€æ¬¡è¯»å–
        if let Some(prediction) = self.predictor.predict(&self.history) {
            // æäº¤é¢„è¯»è¯·æ±‚
            self.submit_prefetch(prediction);
        }
    }
    
    fn submit_prefetch(&self, prediction: ReadPrediction) {
        let mut queue = self.prefetch_queue.lock();
        queue.push_back(PrefetchRequest {
            path: prediction.path,
            offset: prediction.offset,
            size: prediction.size,
            priority: prediction.confidence,
        });
    }
}
```

## æ€§èƒ½ç›‘æ§

### å…³é”®æŒ‡æ ‡
```rust
pub struct IoUringMetrics {
    pub submissions: AtomicU64,
    pub completions: AtomicU64,
    pub sq_full_events: AtomicU64,
    pub cq_overflow_events: AtomicU64,
    pub avg_latency_us: AtomicU64,
    pub p99_latency_us: AtomicU64,
}

impl IoUringMetrics {
    pub fn record_operation(&self, start: Instant, bytes: usize) {
        let duration = start.elapsed();
        let latency_us = duration.as_micros() as u64;
        
        self.completions.fetch_add(1, Ordering::Relaxed);
        
        // æ›´æ–°å»¶è¿Ÿç»Ÿè®¡
        self.update_latency_stats(latency_us);
        
        // è®¡ç®—ååé‡
        let throughput_mbps = (bytes as f64 / duration.as_secs_f64()) / (1024.0 * 1024.0);
        
        if throughput_mbps > 1000.0 {
            tracing::info!("ğŸš€ io_uring: {:.1} MB/s, latency: {} Î¼s", 
                throughput_mbps, latency_us);
        }
    }
}
```

## éƒ¨ç½²ç­–ç•¥

### 1. å†…æ ¸è¦æ±‚
- Linux 5.10+ (åŸºç¡€ io_uring æ”¯æŒ)
- Linux 5.11+ (ä¼˜åŒ–çš„ splice æ”¯æŒ)
- Linux 5.19+ (å®Œæ•´çš„å›ºå®šç¼“å†²åŒºæ”¯æŒ)

### 2. ç¼–è¯‘æ—¶é…ç½®
```bash
# å¯ç”¨ io_uring ç‰¹æ€§
cargo build --release --features io_uring

# æ£€æŸ¥ç³»ç»Ÿæ”¯æŒ
./nfs-cachefs --check-io-uring
```

### 3. è¿è¡Œæ—¶é…ç½®
```bash
# æŒ‚è½½æ—¶å¯ç”¨ io_uring
mount -t cachefs -o nfs_backend=/mnt/nfs,cache_dir=/mnt/nvme/cache,\
nvme_use_io_uring=true,nvme_queue_depth=256,nvme_polling_mode=true \
cachefs /mnt/cached
```

### 4. æ€§èƒ½è°ƒä¼˜
```bash
# ç³»ç»Ÿå‚æ•°ä¼˜åŒ–
echo 2048 > /proc/sys/fs/aio-max-nr
echo 2048 > /proc/sys/fs/aio-nr

# CPU äº²å’Œæ€§è®¾ç½®
taskset -c 0-3 ./nfs-cachefs ...

# å†…å­˜å¤§é¡µé…ç½®
echo 1024 > /proc/sys/vm/nr_hugepages
```

## æµ‹è¯•æ–¹æ¡ˆ

### 1. åŠŸèƒ½æµ‹è¯•
- io_uring å¯ç”¨æ€§æ£€æµ‹
- é™çº§åˆ°ä¼ ç»ŸI/Oçš„å…¼å®¹æ€§
- é”™è¯¯å¤„ç†å’Œæ¢å¤

### 2. æ€§èƒ½æµ‹è¯•
```bash
# åŸºå‡†æµ‹è¯•
fio --name=read --ioengine=io_uring --direct=1 \
    --rw=read --bs=4M --size=10G --numjobs=1

# å¯¹æ¯”æµ‹è¯•
./benchmark.sh --before-uring --after-uring
```

### 3. å‹åŠ›æµ‹è¯•
- é«˜å¹¶å‘è¯»å–åœºæ™¯
- æ··åˆè¯»å†™å·¥ä½œè´Ÿè½½
- é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•

## é£é™©ä¸ç¼“è§£

### 1. æŠ€æœ¯é£é™©
- **å†…æ ¸å…¼å®¹æ€§**: æä¾›è¿è¡Œæ—¶æ£€æµ‹å’Œè‡ªåŠ¨é™çº§
- **ç¨³å®šæ€§é—®é¢˜**: å……åˆ†æµ‹è¯•ï¼Œä¿ç•™ä¼ ç»ŸI/Oè·¯å¾„
- **å¤æ‚åº¦å¢åŠ **: æ¨¡å—åŒ–è®¾è®¡ï¼Œæ¸…æ™°çš„æŠ½è±¡å±‚

### 2. æ€§èƒ½é£é™©
- **å°æ–‡ä»¶æ€§èƒ½**: ä¿ç•™åŸæœ‰ä¼˜åŒ–è·¯å¾„
- **å†…å­˜ä½¿ç”¨**: æ™ºèƒ½ç¼“å†²åŒºç®¡ç†
- **CPUå¼€é”€**: è‡ªé€‚åº”è½®è¯¢ç­–ç•¥

## å®æ–½æ—¶é—´è¡¨

### ç¬¬1å‘¨
- [x] é¡¹ç›®åˆ†æå’Œæ–¹æ¡ˆè®¾è®¡
- [ ] æ·»åŠ  io_uring ä¾èµ–
- [ ] å®ç°åŸºç¡€ io_uring æ¨¡å—

### ç¬¬2å‘¨
- [ ] æ”¹é€ ç¼“å­˜è¯»å–è·¯å¾„
- [ ] å®ç°å›ºå®šç¼“å†²åŒºæ± 
- [ ] åŸºç¡€æ€§èƒ½æµ‹è¯•

### ç¬¬3å‘¨
- [ ] ä¼˜åŒ–ç¼“å­˜å†™å…¥æµç¨‹
- [ ] å®ç°é›¶æ‹·è´ä¼ è¾“
- [ ] é›†æˆæµ‹è¯•

### ç¬¬4-5å‘¨
- [ ] é«˜çº§ç‰¹æ€§å®ç°
- [ ] æ€§èƒ½è°ƒä¼˜
- [ ] æ–‡æ¡£å’Œå‘å¸ƒå‡†å¤‡

## æ€»ç»“

é€šè¿‡é›†æˆ io_uringï¼ŒNFS-CacheFS å°†å®ç°è´¨çš„é£è·ƒï¼š

1. **æè‡´æ€§èƒ½**: æ¥è¿‘ç¡¬ä»¶ç†è®ºæé™
2. **ä½å»¶è¿Ÿ**: å¾®ç§’çº§å“åº”æ—¶é—´
3. **é«˜æ•ˆç‡**: CPUä½¿ç”¨ç‡å¤§å¹…é™ä½
4. **å¯æ‰©å±•**: æ”¯æŒæ›´é«˜å¹¶å‘å’Œåå

è¿™æ˜¯ä¸€ä¸ªæ¸è¿›å¼çš„æ”¹é€ æ–¹æ¡ˆï¼Œç¡®ä¿åœ¨æå‡æ€§èƒ½çš„åŒæ—¶ä¿æŒç³»ç»Ÿç¨³å®šæ€§å’Œå…¼å®¹æ€§ã€‚